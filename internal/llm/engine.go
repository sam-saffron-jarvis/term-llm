package llm

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/samsaffron/term-llm/internal/usage"
)

const (
	defaultMaxTurns    = 20
	stopSearchToolHint = "IMPORTANT: Do not call any tools. Use the information already retrieved and answer directly."
)

// getMaxTurns returns the max turns from request, with fallback to default
func getMaxTurns(req Request) int {
	if req.MaxTurns > 0 {
		return req.MaxTurns
	}
	return defaultMaxTurns
}

// TurnMetrics contains metrics collected during a turn.
type TurnMetrics struct {
	InputTokens  int // Tokens consumed as input this turn
	OutputTokens int // Tokens generated as output this turn
	ToolCalls    int // Number of tools executed this turn
}

// TurnCompletedCallback is called after each turn completes with the messages
// generated during that turn and metrics about the turn.
// turnIndex is 0-based, messages contains assistant message(s) and tool result(s).
type TurnCompletedCallback func(ctx context.Context, turnIndex int, messages []Message, metrics TurnMetrics) error

// Engine orchestrates provider calls and external tool execution.
type Engine struct {
	provider    Provider
	tools       *ToolRegistry
	debugLogger *DebugLogger

	// allowedTools filters which tools can be executed.
	// If nil or empty, all tools are allowed. When set, only listed tools can run.
	// Used by skills with allowed-tools to restrict tool access.
	allowedTools map[string]bool
	allowedMu    sync.RWMutex

	// onTurnCompleted is called after each turn with messages generated.
	// Used for incremental session saving. Protected by callbackMu.
	onTurnCompleted TurnCompletedCallback
	callbackMu      sync.RWMutex
}

// ToolExecutorSetter is an optional interface for providers that need
// tool execution wired up externally (e.g., claude-bin with HTTP MCP).
type ToolExecutorSetter interface {
	SetToolExecutor(func(ctx context.Context, name string, args json.RawMessage) (string, error))
}

func NewEngine(provider Provider, tools *ToolRegistry) *Engine {
	if tools == nil {
		tools = NewToolRegistry()
	}
	e := &Engine{
		provider: provider,
		tools:    tools,
	}

	// Wire up tool executor for providers that need it (e.g., claude-bin HTTP MCP)
	if setter, ok := provider.(ToolExecutorSetter); ok {
		setter.SetToolExecutor(func(ctx context.Context, name string, args json.RawMessage) (string, error) {
			tool, ok := e.tools.Get(name)
			if !ok {
				return "", fmt.Errorf("tool not found: %s", name)
			}
			return tool.Execute(ctx, args)
		})
	}

	return e
}

// RegisterTool adds a tool to the engine's registry.
func (e *Engine) RegisterTool(tool Tool) {
	e.tools.Register(tool)
}

// UnregisterTool removes a tool from the engine's registry.
func (e *Engine) UnregisterTool(name string) {
	e.tools.Unregister(name)
}

// Tools returns the engine's tool registry.
func (e *Engine) Tools() *ToolRegistry {
	return e.tools
}

// SetDebugLogger sets the debug logger for this engine.
func (e *Engine) SetDebugLogger(logger *DebugLogger) {
	e.debugLogger = logger
}

// SetAllowedTools sets the list of tools that can be executed.
// When set, only tools in this list can run; all others are blocked.
// Pass nil or empty slice to allow all tools.
// The list is intersected with registered tools (can't allow unregistered tools).
func (e *Engine) SetAllowedTools(tools []string) {
	e.allowedMu.Lock()
	defer e.allowedMu.Unlock()

	if len(tools) == 0 {
		e.allowedTools = nil
		return
	}

	e.allowedTools = make(map[string]bool, len(tools))
	for _, name := range tools {
		// Only add if tool is registered (intersection with available tools)
		if _, ok := e.tools.Get(name); ok {
			e.allowedTools[name] = true
		}
	}
}

// ClearAllowedTools removes the tool filter, allowing all registered tools.
func (e *Engine) ClearAllowedTools() {
	e.allowedMu.Lock()
	defer e.allowedMu.Unlock()
	e.allowedTools = nil
}

// SetTurnCompletedCallback sets the callback for incremental turn completion.
// The callback receives messages generated each turn for incremental persistence.
// Thread-safe: can be called while streaming is in progress.
func (e *Engine) SetTurnCompletedCallback(cb TurnCompletedCallback) {
	e.callbackMu.Lock()
	e.onTurnCompleted = cb
	e.callbackMu.Unlock()
}

// getCallback returns the current callback under read lock.
func (e *Engine) getCallback() TurnCompletedCallback {
	e.callbackMu.RLock()
	cb := e.onTurnCompleted
	e.callbackMu.RUnlock()
	return cb
}

// IsToolAllowed checks if a tool can be executed under current restrictions.
func (e *Engine) IsToolAllowed(name string) bool {
	e.allowedMu.RLock()
	defer e.allowedMu.RUnlock()

	// No filter means all tools are allowed
	if e.allowedTools == nil {
		return true
	}
	return e.allowedTools[name]
}

// Stream returns a stream, applying external tools when needed.
func (e *Engine) Stream(ctx context.Context, req Request) (Stream, error) {
	if req.DebugRaw {
		DebugRawRequest(req.DebugRaw, e.provider.Name(), e.provider.Credential(), req, "Request")
	}

	caps := e.provider.Capabilities()

	// 1. Handle external search/fetch tool injection
	// If Search is enabled, add web_search and read_url tools to the tool list.
	// The LLM will use them naturally during conversation like any other tool.
	if req.Search {
		needsExternalSearch := !caps.NativeWebSearch || req.ForceExternalSearch
		needsExternalFetch := !caps.NativeWebFetch || req.ForceExternalSearch

		if needsExternalSearch {
			if t, ok := e.tools.Get(WebSearchToolName); ok {
				if !hasToolNamed(req.Tools, WebSearchToolName) {
					req.Tools = append(req.Tools, t.Spec())
				}
			}
		}
		if needsExternalFetch {
			if t, ok := e.tools.Get(ReadURLToolName); ok {
				if !hasToolNamed(req.Tools, ReadURLToolName) {
					req.Tools = append(req.Tools, t.Spec())
				}
			}
		}
	}

	// 2. Decide if we use the agentic loop
	// We use it if request has tools AND provider supports tool calls
	useLoop := len(req.Tools) > 0 && caps.ToolCalls

	if useLoop {
		stream := newEventStream(ctx, func(ctx context.Context, events chan<- Event) error {
			return e.runLoop(ctx, req, events)
		})
		stream = wrapLoggingStream(stream, e.provider.Name(), req.Model)
		return e.wrapDebugLoggingStream(stream), nil
	}

	// 3. Simple stream (no tools or no provider support for tools)
	// Log request for non-agentic requests too
	if e.debugLogger != nil {
		e.debugLogger.LogRequest(e.provider.Name(), req.Model, req)
	}

	stream, err := e.provider.Stream(ctx, req)
	if err != nil {
		return nil, err
	}
	stream = WrapDebugStream(req.DebugRaw, stream)
	stream = wrapLoggingStream(stream, e.provider.Name(), req.Model)

	// Wrap to call turn callback even for simple streams
	// Copy callback under lock to avoid race with SetTurnCompletedCallback
	if cb := e.getCallback(); cb != nil {
		stream = wrapCallbackStream(ctx, stream, cb)
	}

	return e.wrapDebugLoggingStream(stream), nil
}

// wrapCallbackStream wraps a stream to call the turn callback on completion.
// Used for simple (non-agentic) streams to enable incremental session saving.
func wrapCallbackStream(ctx context.Context, inner Stream, cb TurnCompletedCallback) Stream {
	return &callbackStream{
		inner:    inner,
		ctx:      ctx,
		text:     &strings.Builder{},
		metrics:  TurnMetrics{},
		callback: cb,
	}
}

// callbackStream wraps a stream to accumulate text/usage and call callback on EOF.
type callbackStream struct {
	inner    Stream
	ctx      context.Context
	text     *strings.Builder
	metrics  TurnMetrics
	callback TurnCompletedCallback
	done     bool
}

func (s *callbackStream) Recv() (Event, error) {
	event, err := s.inner.Recv()
	if err == io.EOF {
		// Call callback with accumulated content on normal completion
		s.fireCallback()
		return event, err
	}
	if err != nil {
		// Call callback on error too (best-effort save of partial output)
		s.fireCallback()
		return event, err
	}

	// Accumulate text and usage
	if event.Type == EventTextDelta && event.Text != "" {
		s.text.WriteString(event.Text)
	}
	if event.Type == EventUsage && event.Use != nil {
		s.metrics.InputTokens += event.Use.InputTokens
		s.metrics.OutputTokens += event.Use.OutputTokens
	}

	return event, nil
}

// fireCallback invokes the callback once if there's accumulated content.
func (s *callbackStream) fireCallback() {
	if s.callback != nil && !s.done && s.text.Len() > 0 {
		s.done = true
		msg := Message{
			Role:  RoleAssistant,
			Parts: []Part{{Type: PartText, Text: s.text.String()}},
		}
		_ = s.callback(s.ctx, 0, []Message{msg}, s.metrics)
	}
}

func (s *callbackStream) Close() error {
	// Best-effort: fire callback if stream closed without EOF/error
	s.fireCallback()
	return s.inner.Close()
}

// hasToolNamed checks if a tool with the given name exists in the tool list.
func hasToolNamed(tools []ToolSpec, name string) bool {
	for _, t := range tools {
		if t.Name == name {
			return true
		}
	}
	return false
}

func (e *Engine) runLoop(ctx context.Context, req Request, events chan<- Event) error {
	maxTurns := getMaxTurns(req)
	originalToolChoice := req.ToolChoice
	restoredToolChoice := false

	// Copy callback at start - protects against concurrent modification from UI thread
	callback := e.getCallback()

	for attempt := 0; attempt < maxTurns; attempt++ {
		// Prepare turn
		if attempt == maxTurns-1 {
			req.Messages = append(req.Messages, SystemText(stopSearchToolHint))
			if req.LastTurnToolChoice != nil {
				req.ToolChoice = *req.LastTurnToolChoice
			}
		} else if attempt > 0 {
			// Ensure we are in Auto mode for follow-up turns in the loop
			req.ToolChoice = ToolChoice{Mode: ToolChoiceAuto}
		}

		// Log per-turn request state
		// For attempt 0: captures state after applyExternalSearch modifications
		// For attempt > 0: captures tool results appended in previous turn
		if e.debugLogger != nil {
			e.debugLogger.LogTurnRequest(attempt, e.provider.Name(), req.Model, req)
		}

		if req.DebugRaw {
			DebugRawRequest(req.DebugRaw, e.provider.Name(), e.provider.Credential(), req, fmt.Sprintf("Request (turn %d)", attempt))
		}

		stream, err := e.provider.Stream(ctx, req)
		if err != nil {
			return err
		}

		// Collect tool calls and text, forward events, track metrics
		var toolCalls []ToolCall
		var textBuilder strings.Builder
		var reasoningBuilder strings.Builder // For thinking models (OpenRouter reasoning_content)
		var turnMetrics TurnMetrics
		var syncToolsExecuted bool     // Track if tools were executed via sync path (MCP)
		var finishingToolExecuted bool // Track if a finishing tool was executed (agent done)
		var syncToolCalls []ToolCall   // Track sync tool calls for message building
		var syncToolResults []Message  // Track sync tool results for message building
		for {
			event, err := stream.Recv()
			if err == io.EOF {
				break
			}
			if err != nil {
				stream.Close()
				return err
			}
			if event.Type == EventError && event.Err != nil {
				stream.Close()
				return event.Err
			}
			if req.DebugRaw {
				DebugRawEvent(true, event)
			}
			// Track usage metrics
			if event.Type == EventUsage && event.Use != nil {
				turnMetrics.InputTokens += event.Use.InputTokens
				turnMetrics.OutputTokens += event.Use.OutputTokens
			}
			// Accumulate text for callback
			if event.Type == EventTextDelta && event.Text != "" {
				textBuilder.WriteString(event.Text)
			}
			// Accumulate reasoning for thinking models (OpenRouter)
			if event.Type == EventReasoningDelta && event.Text != "" {
				reasoningBuilder.WriteString(event.Text)
			}
			if event.Type == EventToolCall && event.Tool != nil {
				// Check if this is a synchronous tool execution request (from claude_bin MCP)
				if event.ToolResponse != nil {
					// Handle synchronous execution: emit events to TUI and send result back
					call, result, execErr := e.handleSyncToolExecution(ctx, event, events, req.Debug, req.DebugRaw)
					syncToolsExecuted = true
					syncToolCalls = append(syncToolCalls, call)
					// Build result message for this tool call
					if execErr != nil {
						syncToolResults = append(syncToolResults, ToolErrorMessage(call.ID, call.Name, execErr.Error(), nil))
					} else {
						syncToolResults = append(syncToolResults, ToolResultMessage(call.ID, call.Name, result, nil))
					}
					// Check if this was a finishing tool (signals agent completion)
					if e.tools.IsFinishingTool(event.Tool.Name) {
						finishingToolExecuted = true
					}
					continue
				}
				// Normal async collection for other providers
				toolCalls = append(toolCalls, *event.Tool)
				continue
			}
			if event.Type == EventDone {
				continue
			}
			events <- event
		}
		stream.Close()

		// Search is only performed once (either pre-emptively or in first turn)
		req.Search = false

		if len(toolCalls) == 0 && !syncToolsExecuted {
			// No tools called - check if we should restore original tool choice and retry once
			if originalToolChoice.Mode == ToolChoiceName && !restoredToolChoice {
				req.ToolChoice = originalToolChoice
				restoredToolChoice = true
				continue
			}
			// Call callback with final text-only response (no tools)
			if callback != nil && textBuilder.Len() > 0 {
				finalMsg := Message{
					Role:  RoleAssistant,
					Parts: []Part{{Type: PartText, Text: textBuilder.String()}},
				}
				_ = callback(ctx, attempt, []Message{finalMsg}, turnMetrics)
			}
			events <- Event{Type: EventDone}
			return nil
		}

		// If only sync tools were executed (MCP path), decide whether to continue
		if len(toolCalls) == 0 && syncToolsExecuted {
			// Build assistant message with text and sync tool calls
			// This is needed so claude-bin gets proper context when resuming
			assistantMsg := buildAssistantMessage(textBuilder.String(), syncToolCalls, reasoningBuilder.String())
			req.Messages = append(req.Messages, assistantMsg)
			req.Messages = append(req.Messages, syncToolResults...)

			// Call turn completed callback for incremental persistence
			if callback != nil {
				turnMetrics.ToolCalls = len(syncToolCalls)
				turnMessages := []Message{assistantMsg}
				turnMessages = append(turnMessages, syncToolResults...)
				_ = callback(ctx, attempt, turnMessages, turnMetrics)
			}

			// If a finishing tool was executed, we're done (agent completed its task)
			if finishingToolExecuted {
				events <- Event{Type: EventDone}
				return nil
			}

			// Continue the loop - provider will receive updated messages on next turn
			continue
		}

		toolCalls = ensureToolCallIDs(toolCalls)
		toolCalls = dedupeToolCalls(toolCalls)

		// Split into registered (to execute) and unregistered (to passthrough)
		var registered, unregistered []ToolCall
		for _, call := range toolCalls {
			if _, ok := e.tools.Get(call.Name); ok {
				registered = append(registered, call)
			} else {
				unregistered = append(unregistered, call)
			}
		}

		// Forward unregistered tool calls as events
		for i := range unregistered {
			call := unregistered[i]
			DebugToolCall(req.Debug, call)
			events <- Event{Type: EventToolCall, Tool: &call}
		}

		// If nothing to execute, we are done
		if len(registered) == 0 {
			// Call callback with text + unregistered tool calls
			if callback != nil {
				var parts []Part
				if textBuilder.Len() > 0 {
					parts = append(parts, Part{Type: PartText, Text: textBuilder.String()})
				}
				for i := range unregistered {
					call := unregistered[i]
					parts = append(parts, Part{Type: PartToolCall, ToolCall: &call})
				}
				if len(parts) > 0 {
					finalMsg := Message{Role: RoleAssistant, Parts: parts}
					_ = callback(ctx, attempt, []Message{finalMsg}, turnMetrics)
				}
			}
			events <- Event{Type: EventDone}
			return nil
		}

		if attempt == maxTurns-1 {
			return fmt.Errorf("agentic loop exceeded max turns (%d)", maxTurns)
		}

		// Execute registered tools
		for _, call := range registered {
			DebugToolCall(req.Debug, call)
			info := e.getToolPreview(call)

			if events != nil {
				events <- Event{Type: EventToolExecStart, ToolCallID: call.ID, ToolName: call.Name, ToolInfo: info}
			}
		}

		toolResults, err := e.executeToolCalls(ctx, registered, events, req.Debug, req.DebugRaw)
		if err != nil {
			return err
		}

		// Build assistant message with text + tool calls + reasoning
		assistantMsg := buildAssistantMessage(textBuilder.String(), registered, reasoningBuilder.String())
		req.Messages = append(req.Messages, assistantMsg)
		req.Messages = append(req.Messages, toolResults...)

		// Call turn completed callback for incremental persistence
		if callback != nil {
			turnMetrics.ToolCalls = len(registered)
			turnMessages := []Message{assistantMsg}
			turnMessages = append(turnMessages, toolResults...)
			_ = callback(ctx, attempt, turnMessages, turnMetrics)
		}
	}

	return fmt.Errorf("agentic loop ended unexpectedly")
}

// buildAssistantMessage creates an assistant message with text, tool calls, and optional reasoning.
// The reasoning parameter is for thinking models (OpenRouter reasoning_content).
func buildAssistantMessage(text string, toolCalls []ToolCall, reasoning string) Message {
	var parts []Part
	if text != "" || reasoning != "" {
		parts = append(parts, Part{Type: PartText, Text: text, ReasoningContent: reasoning})
	}
	for i := range toolCalls {
		call := toolCalls[i]
		parts = append(parts, Part{Type: PartToolCall, ToolCall: &call})
	}
	return Message{Role: RoleAssistant, Parts: parts}
}

// executeToolCalls executes multiple tool calls, potentially in parallel.
// Note: When executing in parallel, EventToolExecStart/EventToolExecEnd events
// are emitted from concurrent goroutines. While the channel is thread-safe, events
// may arrive in non-deterministic order. Consumers should use ToolCallID to correlate
// start/end events rather than relying on ordering.
func (e *Engine) executeToolCalls(ctx context.Context, calls []ToolCall, events chan<- Event, debug bool, debugRaw bool) ([]Message, error) {
	// Fast path: single call, no concurrency overhead
	if len(calls) == 1 {
		return e.executeSingleToolCall(ctx, calls[0], events, debug, debugRaw)
	}

	// Parallel execution for multiple calls (events may arrive out of order)
	type toolResult struct {
		index   int
		message Message
	}

	var wg sync.WaitGroup
	resultChan := make(chan toolResult, len(calls))

	for i, call := range calls {
		wg.Add(1)
		go func(idx int, c ToolCall) {
			defer wg.Done()
			msgs, _ := e.executeSingleToolCall(ctx, c, events, debug, debugRaw)
			if len(msgs) > 0 {
				resultChan <- toolResult{index: idx, message: msgs[0]}
			}
		}(i, call)
	}

	// Close channel when all goroutines complete
	go func() {
		wg.Wait()
		close(resultChan)
	}()

	// Collect results and maintain original order
	results := make([]Message, len(calls))
	for r := range resultChan {
		results[r.index] = r.message
	}

	return results, nil
}

// executeSingleToolCall executes a single tool call and returns the result message.
func (e *Engine) executeSingleToolCall(ctx context.Context, call ToolCall, events chan<- Event, debug bool, debugRaw bool) ([]Message, error) {
	tool, ok := e.tools.Get(call.Name)
	if !ok {
		errMsg := fmt.Sprintf("Error: tool not registered: %s", call.Name)
		DebugToolResult(debug, call.ID, call.Name, errMsg)
		if events != nil {
			events <- Event{Type: EventToolExecEnd, ToolCallID: call.ID, ToolName: call.Name, ToolInfo: e.getToolPreview(call), ToolSuccess: false}
		}
		return []Message{ToolErrorMessage(call.ID, call.Name, errMsg, call.ThoughtSig)}, nil
	}

	// Check if tool is allowed under current skill restrictions
	if !e.IsToolAllowed(call.Name) {
		errMsg := fmt.Sprintf("Error: tool '%s' is not in the active skill's allowed-tools list", call.Name)
		DebugToolResult(debug, call.ID, call.Name, errMsg)
		if events != nil {
			events <- Event{Type: EventToolExecEnd, ToolCallID: call.ID, ToolName: call.Name, ToolInfo: e.getToolPreview(call), ToolSuccess: false}
		}
		return []Message{ToolErrorMessage(call.ID, call.Name, errMsg, call.ThoughtSig)}, nil
	}

	// Add call ID to context for spawn_agent event bubbling
	toolCtx := ContextWithCallID(ctx, call.ID)
	output, err := tool.Execute(toolCtx, call.Arguments)
	info := e.getToolPreview(call)

	if err != nil {
		errMsg := fmt.Sprintf("Error: %v", err)
		DebugToolResult(debug, call.ID, call.Name, errMsg)
		if events != nil {
			events <- Event{Type: EventToolExecEnd, ToolCallID: call.ID, ToolName: call.Name, ToolInfo: info, ToolSuccess: false}
		}
		return []Message{ToolErrorMessage(call.ID, call.Name, errMsg, call.ThoughtSig)}, nil
	}

	DebugToolResult(debug, call.ID, call.Name, output)
	DebugRawToolResult(debugRaw, call.ID, call.Name, output)
	if events != nil {
		events <- Event{Type: EventToolExecEnd, ToolCallID: call.ID, ToolName: call.Name, ToolInfo: info, ToolSuccess: true, ToolOutput: output}
	}
	return []Message{ToolResultMessage(call.ID, call.Name, output, call.ThoughtSig)}, nil
}

// handleSyncToolExecution handles synchronous tool execution for providers like claude_bin.
// It emits EventToolExecStart/End to the outer channel (for TUI) and sends the result
// back to the provider via the response channel.
// Returns the tool call, result string, and any error that occurred during execution.
func (e *Engine) handleSyncToolExecution(ctx context.Context, event Event, events chan<- Event, debug bool, debugRaw bool) (ToolCall, string, error) {
	call := event.Tool
	callID := event.ToolCallID
	if callID == "" {
		callID = call.ID
	}

	// Get tool preview info
	info := e.getToolPreview(*call)
	if event.ToolInfo != "" {
		info = event.ToolInfo
	}

	// Emit start event to TUI (non-blocking to avoid deadlock if consumer is slow)
	if events != nil {
		select {
		case events <- Event{
			Type:       EventToolExecStart,
			ToolCallID: callID,
			ToolName:   call.Name,
			ToolInfo:   info,
		}:
		default:
			// Event dropped due to slow consumer
		}
	}

	// Look up and execute the tool
	tool, ok := e.tools.Get(call.Name)
	var result string
	var err error

	if !ok {
		err = fmt.Errorf("tool not found: %s", call.Name)
	} else if !e.IsToolAllowed(call.Name) {
		err = fmt.Errorf("tool '%s' is not in the active skill's allowed-tools list", call.Name)
	} else {
		toolCtx := ContextWithCallID(ctx, callID)
		result, err = tool.Execute(toolCtx, call.Arguments)
	}

	// Debug logging
	if err != nil {
		DebugToolResult(debug, callID, call.Name, fmt.Sprintf("Error: %v", err))
	} else {
		DebugToolResult(debug, callID, call.Name, result)
		DebugRawToolResult(debugRaw, callID, call.Name, result)
	}

	// Emit end event to TUI (non-blocking to avoid deadlock if consumer is slow)
	if events != nil {
		select {
		case events <- Event{
			Type:        EventToolExecEnd,
			ToolCallID:  callID,
			ToolName:    call.Name,
			ToolInfo:    info,
			ToolSuccess: err == nil,
			ToolOutput:  result,
		}:
		default:
			// Event dropped due to slow consumer
		}
	}

	// Send result back to provider (claude_bin MCP handler)
	// Use select to avoid blocking if context is canceled and receiver has exited
	select {
	case event.ToolResponse <- ToolExecutionResponse{Result: result, Err: err}:
	case <-ctx.Done():
		// Best-effort: abandon send if context canceled
	}

	// Ensure call has the proper ID (may have been generated)
	returnCall := *call
	returnCall.ID = callID
	return returnCall, result, err
}

func ensureToolCallIDs(calls []ToolCall) []ToolCall {
	for i := range calls {
		if strings.TrimSpace(calls[i].ID) == "" {
			calls[i].ID = fmt.Sprintf("toolcall-%d", i+1)
		}
	}
	return calls
}

func dedupeToolCalls(calls []ToolCall) []ToolCall {
	if len(calls) < 2 {
		return calls
	}
	seen := make(map[string]struct{}, len(calls))
	out := make([]ToolCall, 0, len(calls))
	for _, call := range calls {
		id := strings.TrimSpace(call.ID)
		if id == "" {
			out = append(out, call)
			continue
		}
		if _, ok := seen[id]; ok {
			continue
		}
		seen[id] = struct{}{}
		out = append(out, call)
	}
	return out
}

// getToolPreview returns a preview string for a tool call.
func (e *Engine) getToolPreview(call ToolCall) string {
	if tool, ok := e.tools.Get(call.Name); ok {
		if preview := tool.Preview(call.Arguments); preview != "" {
			if !strings.HasPrefix(preview, "(") {
				return "(" + preview + ")"
			}
			return preview
		}
	}
	return ExtractToolInfo(call)
}

func formatToolArgs(args map[string]any, maxLen, maxParams int) string {
	if len(args) == 0 {
		return ""
	}

	type argPair struct {
		key string
		val string
	}
	var pairs []argPair

	for k, v := range args {
		var valStr string
		switch val := v.(type) {
		case string:
			if val == "" {
				continue
			}
			valStr = val
		case float64:
			if val == float64(int(val)) {
				valStr = fmt.Sprintf("%d", int(val))
			} else {
				valStr = fmt.Sprintf("%g", val)
			}
		case bool:
			valStr = fmt.Sprintf("%v", val)
		default:
			continue
		}

		if len(valStr) > 200 {
			valStr = valStr[:197] + "..."
		}
		pairs = append(pairs, argPair{key: k, val: valStr})
	}

	if len(pairs) == 0 {
		return ""
	}

	sort.Slice(pairs, func(i, j int) bool {
		return pairs[i].key < pairs[j].key
	})

	var result string
	if len(pairs) == 1 {
		result = "(" + pairs[0].val + ")"
	} else {
		var parts []string
		for i, p := range pairs {
			if i >= maxParams {
				parts = append(parts, "...")
				break
			}
			parts = append(parts, p.key+":"+p.val)
		}
		result = "(" + strings.Join(parts, ", ") + ")"
	}

	if len(result) > maxLen {
		result = result[:maxLen-4] + "...)"
	}

	return result
}

// ExtractToolInfo extracts a preview string from tool call arguments.
// Used for displaying tool calls in the UI (e.g., "(path:main.go)" for read_file).
func ExtractToolInfo(call ToolCall) string {
	if len(call.Arguments) == 0 {
		return ""
	}

	var args map[string]any
	if err := json.Unmarshal(call.Arguments, &args); err != nil {
		return ""
	}

	return formatToolArgs(args, 500, 5)
}

// loggingStream wraps a stream to accumulate usage and log it on completion
type loggingStream struct {
	inner           Stream
	logger          *usage.Logger
	providerName    string
	model           string
	trackedExternal string // "claude-code", "codex", "gemini-cli", or "" for direct API

	// Accumulated usage (multiple EventUsage events in agentic loops)
	totalInput      int
	totalOutput     int
	totalCacheRead  int
	totalCacheWrite int
	logged          bool // Prevent double-logging
}

func (s *loggingStream) Recv() (Event, error) {
	event, err := s.inner.Recv()

	// Accumulate usage from each EventUsage
	if err == nil && event.Type == EventUsage && event.Use != nil {
		s.totalInput += event.Use.InputTokens
		s.totalOutput += event.Use.OutputTokens
		s.totalCacheRead += event.Use.CachedInputTokens
	}

	// Log on EOF (stream complete) or EventDone
	if (err == io.EOF || (err == nil && event.Type == EventDone)) && !s.logged {
		s.flush()
	}

	return event, err
}

func (s *loggingStream) Close() error {
	// Also flush on explicit close (in case EOF wasn't received)
	if !s.logged {
		s.flush()
	}
	return s.inner.Close()
}

func (s *loggingStream) flush() {
	if s.totalInput == 0 && s.totalOutput == 0 {
		return // Nothing to log
	}
	s.logged = true
	_ = s.logger.Log(usage.LogEntry{
		Timestamp:           time.Now(),
		Model:               s.model,
		Provider:            s.providerName,
		InputTokens:         s.totalInput,
		OutputTokens:        s.totalOutput,
		CacheReadTokens:     s.totalCacheRead,
		CacheWriteTokens:    s.totalCacheWrite,
		TrackedExternallyBy: s.trackedExternal,
	})
}

// wrapLoggingStream wraps a stream with usage logging
func wrapLoggingStream(inner Stream, providerName, model string) Stream {
	// If model is empty, use providerName as the model identifier
	// This helps identify what was used when providers auto-select models
	if model == "" {
		model = providerName
	}
	return &loggingStream{
		inner:           inner,
		logger:          usage.DefaultLogger(),
		providerName:    providerName,
		model:           model,
		trackedExternal: usage.GetTrackedExternallyBy(providerName),
	}
}

// wrapDebugLoggingStream wraps a stream with debug logging if enabled
func (e *Engine) wrapDebugLoggingStream(inner Stream) Stream {
	if e.debugLogger == nil {
		return inner
	}
	return &debugLoggingStream{
		inner:  inner,
		logger: e.debugLogger,
	}
}

// debugLoggingStream wraps a stream to log events for debugging
type debugLoggingStream struct {
	inner  Stream
	logger *DebugLogger
}

func (s *debugLoggingStream) Recv() (Event, error) {
	event, err := s.inner.Recv()
	if err == nil {
		s.logger.LogEvent(event)
	}
	return event, err
}

func (s *debugLoggingStream) Close() error {
	return s.inner.Close()
}
